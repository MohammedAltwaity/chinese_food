#!/usr/bin/env python3
"""
Flask + PiCamera2 Streaming and Analysis Server (rewritten)
 - live MJPEG stream w/ FPS overlay
 - burst capture, save raw frames
 - select top-N sharp frames -> saved to `best/`
 - extract all faces from those top frames -> saved to `extracted_faces/`
 - select the MOST FRONTAL face (symmetry heuristic) -> saved to `final_result/`
 - safe Haar cascade handling (auto-download if missing)
"""

from flask import Flask, Response, render_template_string, request, jsonify
from picamera2 import Picamera2
import cv2
import threading
import time
import os
import urllib.request
import numpy as np

# ---------------------------
# CONFIGURATION
# ---------------------------
CAPTURE_BURST_COUNT = 10
CAPTURE_DURATION = 1.2
TOP_N = 5
DEFAULT_MARGIN = 0.1
FALLBACK_ANGLES = [-30, 30, -15, 15]
HAAR_CASCADE_PATH = "/home/pi/mohammed/haarcascade_frontalface_default.xml"
HAAR_DOWNLOAD_URL = "https://github.com/opencv/opencv/raw/master/data/haarcascades/haarcascade_frontalface_default.xml"

# ---------------------------
# FOLDERS
# ---------------------------
CAPTURE_FOLDER = "captured_images"
BEST_FOLDER = "best"
EXTRACTED_FOLDER = "extracted_faces"
FINAL_FOLDER = "final_result"

for d in (CAPTURE_FOLDER, BEST_FOLDER, EXTRACTED_FOLDER, FINAL_FOLDER):
    os.makedirs(d, exist_ok=True)

# ---------------------------
# FLASK APP
# ---------------------------
app = Flask(__name__)

# ---------------------------
# CAMERA SETUP
# ---------------------------
picam2 = Picamera2()
config = picam2.create_video_configuration(
    main={"size": (640, 480), "format": "XRGB8888"},
    buffer_count=2
)
picam2.configure(config)
picam2.start()

latest_frame = None
frame_lock = threading.Condition()

# ---------------------------
# UTIL / HAAR HANDLING
# ---------------------------
def ensure_haar(haar_path=HAAR_CASCADE_PATH):
    """Ensure Haar cascade exists and is non-empty; try to download if missing."""
    if os.path.exists(haar_path) and os.path.getsize(haar_path) > 100:
        return True
    try:
        print(f"[INFO] Haar cascade missing or empty. Downloading to {haar_path} ...")
        os.makedirs(os.path.dirname(haar_path), exist_ok=True)
        urllib.request.urlretrieve(HAAR_DOWNLOAD_URL, haar_path)
        ok = os.path.exists(haar_path) and os.path.getsize(haar_path) > 100
        if ok:
            print("[INFO] Haar cascade downloaded successfully.")
        else:
            print("[ERROR] Haar cascade download failed or file too small.")
        return ok
    except Exception as e:
        print(f"[ERROR] Failed to download Haar cascade: {e}")
        return False

def load_cascade(haar_path=HAAR_CASCADE_PATH):
    """Return a cv2.CascadeClassifier or None if failed."""
    if not ensure_haar(haar_path):
        return None
    cascade = cv2.CascadeClassifier(haar_path)
    if cascade.empty():
        print("[ERROR] CascadeClassifier failed to load (empty).")
        return None
    return cascade

# ---------------------------
# IMAGE / FACE HELPERS
# ---------------------------
def save_frame(frame, folder=CAPTURE_FOLDER, prefix="frame"):
    """Save a frame with timestamped filename and return full path."""
    timestamp = time.strftime("%Y%m%d-%H%M%S-%f")
    filename = f"{prefix}_{timestamp}.jpg"
    path = os.path.join(folder, filename)
    cv2.imwrite(path, frame)
    return path

def image_quality(image):
    """Return sharpness estimate using Laplacian variance (higher = sharper)."""
    try:
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    except Exception:
        return 0
    return float(cv2.Laplacian(gray, cv2.CV_64F).var())

def rotate_image(image, angle):
    h, w = image.shape[:2]
    M = cv2.getRotationMatrix2D((w//2, h//2), angle, 1.0)
    return cv2.warpAffine(image, M, (w, h), flags=cv2.INTER_LINEAR, borderMode=cv2.BORDER_REPLICATE)

def extract_all_faces_from_image(image, cascade, margin=DEFAULT_MARGIN):
    """
    Detect all faces in `image` using provided cascade (no rotation).
    Returns list of face crops (BGR numpy arrays).
    """
    crops = []
    if cascade is None:
        return crops
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    rects = cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30,30))
    for (x, y, w, h) in rects:
        m_w, m_h = int(w * margin), int(h * margin)
        x1, y1 = max(x - m_w, 0), max(y - m_h, 0)
        x2, y2 = min(x + w + m_w, image.shape[1]), min(y + h + m_h, image.shape[0])
        crops.append(image[y1:y2, x1:x2])
    return crops

def extract_largest_face_with_rotation(image, cascade, margin=DEFAULT_MARGIN, fallback_angles=FALLBACK_ANGLES):
    """
    Try the original + fallback rotations and return the largest face crop found.
    Returns the crop (BGR) or None if no face detected.
    """
    if cascade is None:
        return None
    angles = [0] + list(fallback_angles)
    best_crop = None
    best_area = 0
    for a in angles:
        img = rotate_image(image, a) if a != 0 else image
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        rects = cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30,30))
        if rects is None or len(rects) == 0:
            continue
        x, y, w, h = max(rects, key=lambda r: r[2]*r[3])
        area = w * h
        if area > best_area:
            m_w, m_h = int(w * margin), int(h * margin)
            x1, y1 = max(x - m_w, 0), max(y - m_h, 0)
            x2, y2 = min(x + w + m_w, img.shape[1]), min(y + h + m_h, img.shape[0])
            best_crop = img[y1:y2, x1:x2]
            best_area = area
    return best_crop

def select_most_frontal_face(folder=EXTRACTED_FOLDER, resize_to=128):
    """
    Select most frontal face using horizontal symmetry heuristic:
    - For each face image, convert to grayscale, resize to (resize_to, resize_to),
      compute mean absolute difference between the image and its mirrored version.
    - Lower score => more symmetric => more frontal.
    Returns path to chosen image (full path) or None.
    """
    files = [os.path.join(folder, f) for f in sorted(os.listdir(folder)) if f.lower().endswith(".jpg")]
    if not files:
        return None

    best_score = float("inf")
    best_path = None

    for fpath in files:
        img = cv2.imread(fpath)
        if img is None:
            continue
        try:
            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
            resized = cv2.resize(gray, (resize_to, resize_to), interpolation=cv2.INTER_AREA)
            flipped = cv2.flip(resized, 1)
            score = float(np.mean(np.abs(resized.astype(np.float32) - flipped.astype(np.float32))))
        except Exception:
            continue
        # smaller score => more symmetric / frontal
        if score < best_score:
            best_score = score
            best_path = fpath

    return best_path

# ---------------------------
# CAMERA STREAM THREAD
# ---------------------------
def update_camera():
    global latest_frame
    prev_time = time.time()
    while True:
        try:
            frame = picam2.capture_array()
        except Exception:
            frame = None
        if frame is not None:
            frame = cv2.cvtColor(frame, cv2.COLOR_BGRA2BGR)
            curr_time = time.time()
            fps = 1.0 / (curr_time - prev_time) if curr_time - prev_time > 0 else 0.0
            prev_time = curr_time
            cv2.putText(frame, f"FPS:{fps:.2f}", (10,30),
                        cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0,0,255), 3, cv2.LINE_AA)
            with frame_lock:
                latest_frame = frame
                frame_lock.notify_all()
        time.sleep(0.01)

# ---------------------------
# HTML TEMPLATE
# ---------------------------
HTML_TEMPLATE = """
<!DOCTYPE html>
<html>
<head>
<title>Pi Camera Stream</title>
<style>
body { font-family: 'Segoe UI', Tahoma, sans-serif; background:#121212; color:#E0E0E0; margin:0; }
.top-bar { display:flex; align-items:center; gap:20px; padding:20px; }
#video { border:2px solid #333; width:480px; height:360px; background:#1E1E1E; object-fit:cover; }
button { padding:10px 20px; font-size:16px; border-radius:8px; background:#3D5AFE; color:white; border:none; cursor:pointer; }
button:hover { background:#5C6BC0; }
.info { padding:10px 20px; }
#status { font-weight:bold; color:#00E676; margin-bottom:8px; }
#result { background:#1E1E1E; padding:10px; border-radius:6px; font-family:monospace; white-space:pre-wrap; max-width:600px; border:1px solid #333; }
img.preview { max-width:200px; border:1px solid #444; margin-top:8px; display:block; }
</style>
</head>
<body>
<div class="top-bar">
<img id="video" src="/video_feed" alt="Video Feed">
<div>
<button onclick="capture()">Capture & Analyze</button>
<div class="info">
<p id="status">Waiting...</p>
<div><b>Result:</b></div>
<div id="result">None</div>
</div>
</div>
</div>
<script>
function capture() {
    document.getElementById("status").innerText="Capturing...";
    document.getElementById("result").innerText="Waiting...";
    fetch("/", {method:"POST"})
        .then(r=>r.json())
        .then(data=>{
            document.getElementById("status").innerText="Done.";
            document.getElementById("result").innerText=JSON.stringify(data.result, null, 2);
            // show final_result preview if present
            if (data.result && data.result.final_result) {
                const img = document.createElement("img");
                img.src = "/static/" + data.result.final_result;
                img.className = "preview";
                const resultDiv = document.getElementById("result");
                // remove previous preview if any
                const prev = document.querySelector(".preview");
                if (prev) prev.remove();
                resultDiv.appendChild(img);
            }
        })
        .catch(err=>{
            document.getElementById("status").innerText="Error.";
            console.error(err);
        });
}
</script>
</body>
</html>
"""

# ---------------------------
# FLASK ROUTES
# ---------------------------
@app.route("/", methods=["GET", "POST"])
def index_route():
    if request.method == "POST":
        # 1) Capture burst
        frames = []
        interval = CAPTURE_DURATION / max(1, CAPTURE_BURST_COUNT)
        for _ in range(CAPTURE_BURST_COUNT):
            try:
                frame = picam2.capture_array()
            except Exception:
                frame = None
            if frame is not None:
                frames.append(cv2.cvtColor(frame, cv2.COLOR_BGRA2BGR))
            time.sleep(interval)

        # 2) Save raw frames
        [save_frame(f, folder=CAPTURE_FOLDER, prefix=f"frame_{i}") for i, f in enumerate(frames)]

        # 3) Select top-N sharpest frames
        frames_sorted = sorted(frames, key=image_quality, reverse=True)[:TOP_N]

        # Prepare cascade once
        cascade = load_cascade()
        best_paths = []
        extracted_face_paths = []

        # 4) For each top frame: save full frame to BEST_FOLDER and extract faces
        for i, f in enumerate(frames_sorted):
            # Save the full sharp frame to best/
            best_path = save_frame(f, folder=BEST_FOLDER, prefix=f"best_{i}")
            best_paths.append(best_path)

            # Extract ALL faces (no rotation) from this frame and save to extracted_faces/
            faces = extract_all_faces_from_image(f, cascade, margin=DEFAULT_MARGIN)
            for j, face_crop in enumerate(faces):
                face_path = save_frame(face_crop, folder=EXTRACTED_FOLDER, prefix=f"face_{i}_{j}")
                extracted_face_paths.append(face_path)

        # 5) Choose the MOST FRONTAL face among extracted ones (symmetry heuristic)
        final_src_path = select_most_frontal_face(folder=EXTRACTED_FOLDER)
        final_filename = None
        if final_src_path:
            # copy to FINAL_FOLDER with timestamped name
            img = cv2.imread(final_src_path)
            if img is not None:
                final_filename = os.path.basename(save_frame(img, folder=FINAL_FOLDER, prefix="final_face"))
        else:
            # No faces found or nothing selected
            final_filename = None

        # 6) Build API response
        api_result = send_images_to_simulated_api(best_paths)
        api_result["extracted_faces"] = [os.path.basename(p) for p in extracted_face_paths]
        api_result["final_result"] = final_filename

        # also make final_result available in static route by copying filename (Flask static serves from ./static by default)
        # to keep it simple, create ./static if missing and copy the selected final file there for preview
        if final_filename:
            try:
                static_dir = os.path.join(os.getcwd(), "static")
                os.makedirs(static_dir, exist_ok=True)
                src = os.path.join(FINAL_FOLDER, final_filename)
                dst = os.path.join(static_dir, final_filename)
                # copy binary
                with open(src, "rb") as fr, open(dst, "wb") as fw:
                    fw.write(fr.read())
            except Exception as e:
                print(f"[WARN] Could not copy final_result to static/: {e}")

        return jsonify({"result": api_result})

    return render_template_string(HTML_TEMPLATE)

@app.route("/video_feed")
def video_feed():
    """MJPEG streaming route"""
    def generate_frames():
        global latest_frame
        while True:
            with frame_lock:
                if latest_frame is None:
                    frame_lock.wait()
                    continue
                frame = latest_frame.copy()
            _, buffer = cv2.imencode(".jpg", frame)
            yield (b"--frame\r\nContent-Type: image/jpeg\r\n\r\n" + buffer.tobytes() + b"\r\n")
            time.sleep(0.03)
    return Response(generate_frames(), mimetype="multipart/x-mixed-replace; boundary=frame")

# ---------------------------
# MAIN
# ---------------------------
if __name__ == "__main__":
    # ensure haar is present at startup (optional)
    ensure_haar(HAAR_CASCADE_PATH)
    threading.Thread(target=update_camera, daemon=True).start()
    app.run(host="0.0.0.0", port=5001, threaded=True)
